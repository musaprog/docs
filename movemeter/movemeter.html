<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.1">
<title>movemeter.movemeter API documentation</title>
<meta name="description" content="Movemeter Python API â€¦">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>movemeter.movemeter</code></h1>
</header>
<section id="section-intro">
<p>Movemeter Python API</p>
<p>The Movemeter class here does cross-correlation (or template matching)
based motion analysis. You can use it in your own Python programs.</p>
<h2 id="alternatives">Alternatives</h2>
<p>For graphical user interface, use tkgui.py
For direct command line use, use cli.py</p>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="movemeter.movemeter.Movemeter"><code class="flex name class">
<span>class <span class="ident">Movemeter</span></span>
<span>(</span><span>upscale=1, cc_backend='OpenCV', imload_backend='stackread', absolute_results=False, tracking_rois=False, template_method='first', subtract_previous=False, multiprocess=False, print_callback=&lt;built-in function print&gt;, preblur=0, max_movement=None, max_rotation=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A Python API for motion analysis.</p>
<p>Movemeter analyses mainly translational motion using 2D
cross-correlation (aka. template matching). Brightness analysis and
rotational movement analysis are also supported.</p>
<p>The actual motion analaysis is performed by an backend (default
the opencv backend). Similarly, there are backends for image
loading.</p>
<h2 id="example">Example</h2>
<pre><code>meter = Movemeter()                 # Create instance
meter.set_data(image_stacks, ROIs)  # Set data and ROIs
meter.measure_movement(0)           # Run analysis on stack 0
</code></pre>
<p>Many of the attributes can be set at the init or then
modified after the meter is created.</p>
<p>The set_data(stacks, ROIs) can be hard to get right - see its
docstring for more clarification</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>upscale</code></strong> :&ensp;<code>int</code> or <code>float</code></dt>
<dd>Image upscaling used in motion analysis. Enables subpixel
resolution. For example, with the upscale value 10, the smallest
reportable motion step is 1/10 of a pixel. Higher are slow down
the analysis and use more RAM memory.</dd>
<dt><strong><code>cc_backend</code></strong> :&ensp;<code>string</code></dt>
<dd>Motion analysis backend. "OpenCV"</dd>
<dt><strong><code>im_backend</code></strong> :&ensp;<code>string</code> or <code>callable</code></dt>
<dd>Image loading backend. If string, "stackread",
"OpenCV" or "tifffile".</dd>
<dt><strong><code>absolute_results</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, return results in absolute image coordinates. If false,
returns results relative to the corresponding ROI.</dd>
<dt><strong><code>tracking_rois</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, ROIs are shifted between frames, following the moving
features. If False, the ROIs are stationary.</dd>
<dt><strong><code>template_method</code></strong> :&ensp;<code>string</code></dt>
<dd>
<p>Template image creation method used in the motion analysis.</p>
<p>If string:
'first': Use the first image (default)
+ Good even when frame-to-frame displacement are small
'previous': Use the frame before the current frame.
+ Good when the object changes over time
- Bad when frame-to-frame displacements are small
'mean': Calculate the mean frame over the whole stack
+ Good when frames are very noise
- Bad when movement too large</p>
<p>New since movemeter v0.6.0.
The prior versions' attribute called <code>compare_to_first</code> corresponded
to template_method='first' when set to True and to
template_method='previous' when set to False.</p>
</dd>
<dt><strong><code>subtract_previous</code></strong> :&ensp;<code>bool</code></dt>
<dd>Special treatment for when there's a faint moving feature on a static
background.</dd>
<dt><strong><code>multiprocess</code></strong> :&ensp;<code>int</code></dt>
<dd>If 0 then no multiprocessing. Otherwise, the number of parallel
processes. Note that there may be some multiprocessing alread
at the cc_backend level. If used, avoid adding any non-pickable
or heavy attributes to the instances of this class.</dd>
<dt><strong><code>print_callback</code></strong> :&ensp;<code>callable</code></dt>
<dd>Print function to convey the progress.
By default, this is the built-in print function.</dd>
<dt><strong><code>preblur</code></strong> :&ensp;<code>False</code> or <code>float</code></dt>
<dd>Standard deviation of the Gaussian blur kernel, see
scipy.ndimage.gaussian_filter Requires an optional dependency
to scipy to work.</dd>
<dt><strong><code>max_movement</code></strong> :&ensp;<code>None</code> or <code>int</code></dt>
<dd>If not None, in pixels, the maximum expected per-frame
(compare_to_first=False) or total (compare_to_first=True) motion
analysis result in pixel. Essentially crops the source image
around the ROI. Use leads to increased performance reliability.
Too small values small values will truncated and underestimated
motion, too large can wrong matches.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Movemeter:
    &#39;&#39;&#39;A Python API for motion analysis.

    Movemeter analyses mainly translational motion using 2D
    cross-correlation (aka. template matching). Brightness analysis and
    rotational movement analysis are also supported.

    The actual motion analaysis is performed by an backend (default
    the opencv backend). Similarly, there are backends for image
    loading.


    Example
    -------
        meter = Movemeter()                 # Create instance
        meter.set_data(image_stacks, ROIs)  # Set data and ROIs
        meter.measure_movement(0)           # Run analysis on stack 0

    Many of the attributes can be set at the init or then
    modified after the meter is created.

    The set_data(stacks, ROIs) can be hard to get right - see its
    docstring for more clarification


    Attributes
    ----------
    upscale : int or float
        Image upscaling used in motion analysis. Enables subpixel
        resolution. For example, with the upscale value 10, the smallest
        reportable motion step is 1/10 of a pixel. Higher are slow down
        the analysis and use more RAM memory.
    cc_backend : string
        Motion analysis backend. &#34;OpenCV&#34;
    im_backend : string or callable
        Image loading backend. If string, &#34;stackread&#34;,
        &#34;OpenCV&#34; or &#34;tifffile&#34;.
    absolute_results : bool
        If True, return results in absolute image coordinates. If false,
        returns results relative to the corresponding ROI.
    tracking_rois : bool
        If True, ROIs are shifted between frames, following the moving
        features. If False, the ROIs are stationary.
    template_method : string
        Template image creation method used in the motion analysis.

        If string:
        &#39;first&#39;: Use the first image (default)
                + Good even when frame-to-frame displacement are small
        &#39;previous&#39;: Use the frame before the current frame.
                + Good when the object changes over time
                - Bad when frame-to-frame displacements are small
        &#39;mean&#39;: Calculate the mean frame over the whole stack
                + Good when frames are very noise
                - Bad when movement too large

        New since movemeter v0.6.0.
            The prior versions&#39; attribute called `compare_to_first` corresponded
            to template_method=&#39;first&#39; when set to True and to
            template_method=&#39;previous&#39; when set to False.

    subtract_previous : bool
        Special treatment for when there&#39;s a faint moving feature on a static
        background.
    multiprocess : int
        If 0 then no multiprocessing. Otherwise, the number of parallel
        processes. Note that there may be some multiprocessing alread
        at the cc_backend level. If used, avoid adding any non-pickable
        or heavy attributes to the instances of this class.
    print_callback : callable
        Print function to convey the progress.
        By default, this is the built-in print function.
    preblur : False or float
        Standard deviation of the Gaussian blur kernel, see
        scipy.ndimage.gaussian_filter Requires an optional dependency
        to scipy to work.
    max_movement : None or int
        If not None, in pixels, the maximum expected per-frame
        (compare_to_first=False) or total (compare_to_first=True) motion
        analysis result in pixel. Essentially crops the source image
        around the ROI. Use leads to increased performance reliability.
        Too small values small values will truncated and underestimated
        motion, too large can wrong matches.
    &#39;&#39;&#39; 

    measure_brightness_opt = {
            &#39;relative&#39;: [&#39;absolute&#39;, &#39;roi&#39;, &#39;roimin&#39;],
            }

    def __init__(
            self,
            upscale=1,
            cc_backend=&#39;OpenCV&#39;,
            imload_backend=&#39;stackread&#39;,
            absolute_results=False,
            tracking_rois=False,
            template_method=&#39;first&#39;,
            subtract_previous=False,
            multiprocess=False,
            print_callback=print,
            preblur=0,
            max_movement=None,
            max_rotation=None
            ):

        # Initialize attributes to defaults or given values
        self.upscale = upscale
        self.cc_backend = cc_backend
        self.im_backend = imload_backend
        self.absolute_results = absolute_results
        self.tracking_rois = tracking_rois
        self.template_method = template_method
        self.subtract_previous = subtract_previous
        self.multiprocess = multiprocess
        self.print_callback = print_callback
        self.preblur=preblur
        self.max_movement = max_movement
        self.max_rotation = max_rotation

        # Cross-correlation backend
        self._find_location, self._find_rotation = get_cc_backend(
                cc_backend)


    def _imread(self, fn):
        &#39;&#39;&#39;Wraps the image loading backend (self._imload).
        
        Arguments
        ---------
        fn : string
            Filename of the stack or image to read.

        Returns
        -------
        stack : iterable
            Returns something that when you iterate over it, it returns
            valid images
        &#39;&#39;&#39;

        # Image loading backend
        if self.im_backend == &#34;stackread&#34;:
            imload = stackread
        else: 
            imload = get_im_backend(imload_backend)

        if isinstance(fn, str):
            return imload(fn)
        elif isinstance(fn, np.ndarray):
            return fn
        elif hasattr(fn, &#39;__iter__&#39;) or hasattr(fn, &#39;__getitem__&#39;):
            return fn
        else:
            print(f&#39;Warning! Unkown fn: {fn}&#39;)
            return fn

        return image

    def _im_preprocess(image):
        &#39;&#39;&#39;Peform preprocessing on the image before the cc backend

        FIXME: Not currently called from anywhere in the code
        &#39;&#39;&#39;
        # FIXME Normalization not sure if needed
        normalize = False
        if normalize:
            image[i] -= np.min(image[i])
            image[i] = (image[i] / np.max(image[i])) * 1000
            image[i] = image[i].astype(np.float32)

        if self.preblur and scipy:
            image[i] = scipy.ndimage.gaussian_filter(
                    image[i], sigma=self.preblur)
        
        return image
       
    
    def create_mask_image(self, image_fns):
        &#39;&#39;&#39;Creates a min-mask image

        The problem sometimes with cross-correlation analysis is that
        the moving features are semi-transparent or faint while there&#39;s
        a stationary, strong-featured background.

        Subtracting the min-mask image of a stack can be used to remove
        some stationary features -&gt; Working motion detection.

        Seems to work well with microsaccades X-ray projections data.

        Arguments
        ---------
        image_fns : list of strings
            Filenames of the images in the stack

        Returns
        -------
        mask_image : 2D numpy array
            Min image of the stack
        &#39;&#39;&#39;

        mask_image = self._imread(image_fns[0])
        mask_image = np.min(mask_image, axis=0)

        for fn in image_fns[1:]:
            for image in self._imread(fn):
                mask_image = np.min([mask_image, image], axis=0)
        
        return mask_image


    def _measure_movement_optimized_xray_data(
            self, image_fns, ROIs, max_movement=False,
            results_list=None, worker_i=0, messages=[],
            _rotation=False):
        &#39;&#39;&#39;Optimized version for many ROIs (once iterate over images)
        &#39;&#39;&#39;

        results = []

        if worker_i == False:
            nexttime = time.time()

        if self.subtract_previous:
            mask_image = self.create_mask_image(image_fns)
            previous_image = self._imread(image_fns[0])[0] - mask_image
        else:
            previous_image = self._imread(image_fns[0])[0]

        previous_image = previous_image.astype(np.float32, copy=False)

        if not _rotation:
            X = [[] for roi in ROIs]
            Y = [[] for roi in ROIs]
        else:
            R = [[] for roi in ROIs]

        for i, fn in enumerate(image_fns[0:]):

            for image in self._imread(fn):

                image = image.astype(np.float32, copy=False)
                if self.subtract_previous:
                    image = image - mask_image
                
                for i_roi, ROI in enumerate(ROIs):
                    
                    if worker_i == False and nexttime &lt; time.time():
                        percentage = int(100*(i*len(ROIs) + i_roi) / (len(ROIs)*len(image_fns)))
                        message = &#39;Process #1 out of {}, frame {}/{}, in ROI {}/{}. Done {}%&#39;.format(
                                int(self.multiprocess), i+1,len(image_fns),i_roi+1,len(ROIs),int(percentage))
                        messages.append(message)
                        nexttime = time.time() + 2

                    
                    if not _rotation:
                        x, y = self._find_location(image, ROI, previous_image, 
                                max_movement=max_movement, upscale=self.upscale)

                        X[i_roi].append(x)
                        Y[i_roi].append(y)
 
                        if self.tracking_rois:
                            ROIs[i_roi] = [x, y, ROI[2], ROI[3]]

                        print(&#39;{} {}&#39;.format(x,y))
                    else:
                        r = self._find_rotation(
                                image, [int(c) for c in ROI], previous_image, max_movement=max_movement, upscale=self.upscale, max_rotation=self.max_rotation)
                        R.append(r)
                        print(r)

                       
               
                if self.template_method == &#39;first&#39;:
                    # Shortcut for using the first frame as a template
                    pass
                elif self.template_method == &#39;previous&#39;:
                    # Shortcut for using the previous image as a template
                    previous_image = image
        
        if not _rotation:
            for x,y in zip(X,Y):
            
                x = np.asarray(x)
                y = np.asarray(y)
                
                if not self.absolute_results:
                    x = x-x[0]
                    y = y-y[0]
                    
                    if self.template_method == &#39;previous&#39;:
                        x = np.cumsum(x)
                        y = np.cumsum(y)

                results.append([x.tolist(), y.tolist()])
        else:
            raise NotImplementedError

        if results_list is not None:
            results_list[worker_i] = results
            return None

        return results


    def _measure_movement(self, image_fns, ROIs, max_movement=False, _rotation=False):
        &#39;&#39;&#39;Measure movement for 1 or few ROIs.

        This vanilla version is there just to check that the optimized
        version works.
        &#39;&#39;&#39;
       
        results = []

        # Number of frames hiding in the stacks, not apparent from the image
        # file count. Can change during the analysis while reading images.
        N_stacked = 0
 
        if self.subtract_previous:
            mask_image = self.create_mask_image(image_fns)

        for i_roi, ROI in enumerate(ROIs):
            print(&#39;  _measureMovement: {}/{}&#39;.format(i_roi+1, len(ROIs)))
            if self.template_method == &#39;first&#39;:
                previous_image = self._imread(image_fns[0])[0]
            elif self.template_method == &#39;mean&#39;:
                # Fixme: blows up if huge stack that doesnt fit in RAM
                images = []
                for fn in image_fns:
                    for image in self._imread(fn):
                        images.append(image)
                previous_image = np.mean(images, axis=0)

            previous_image = previous_image.astype(np.float32, copy=False)
            X = []
            Y = []
            R = [] # rotations

            i_frame = 0

            for fn in image_fns[0:]:

                images = self._imread(fn)
                N_stacked += len(images) - 1
                  
                for image in images:

                    image = image.astype(np.float32, copy=False)

                    print(&#39;ROI IS {}&#39;.format(ROI))
                    print(&#39;Frame {}/{}&#39;.format(i_frame, len(image_fns)+N_stacked))
                    
                    if self.template_method == &#39;previous&#39;:
                        if self.subtract_previous:
                            # FIXME Possible bug here
                            previous_image = image -  mask_image
                        else:
                            previous_image = image
                    
                    if self.subtract_previous:
                        image = image - mask_image
                    
                    if not _rotation:
                        x, y = self._find_location(image, [int(c) for c in ROI], previous_image, 
                                max_movement=max_movement, upscale=self.upscale)
                        X.append(x)
                        Y.append(y)

                        if self.tracking_rois:
                            #print(&#39;roi tracking&#39;)
                            #raise NotImplementedError
                            ROI = [x, y, ROI[2], ROI[3]]

                        print(&#39;{} {}&#39;.format(x,y))
                    else:
                        r = self._find_rotation(
                                image, [int(c) for c in ROI], previous_image, max_movement=max_movement, upscale=self.upscale, max_rotation=self.max_rotation)
                        R.append(r)
                        print(r)

                    i_frame += 1

            if not _rotation:
                X = np.asarray(X)
                Y = np.asarray(Y)

                if not self.absolute_results:
                    X = X-X[0]
                    Y = Y-Y[0]

                    if self.template_method == &#39;previous&#39;:
                        X = np.cumsum(X)
                        Y = np.cumsum(Y)

                results.append([X.tolist(), Y.tolist()])

            else:
                results.append(R)

        return results



    def set_data(self, stacks, ROIs):
        &#39;&#39;&#39; Set stack filenames and ROIs (regions of interest) to be analysed.

        Arguments
        ---------
        stacks : list of lists of filenames
            List of filename lists. In format
            [
              [stack1_im1, stack1_im2...],
              [stack2_im1, stack2_im2], ...
            ]
        ROIs : list of lists of ROIs
            [
              [ROI1_for_stack1, ROI2_for_stack1, ...],
              [ROI1_for_stack2, ...], ...
            ]

            ROI format: (x, y, w, h)
        
            If the list has length, it means use the same provided
            ROIs for all stacks.

        Example 1 - One stack made separate images, one roi
        ----------------------------------------------------
            stacks = [[&#39;frame1.tif&#39;, &#39;frame2.tif&#39;, ...]]
            ROIs = [[(0,0,24,24)]]

        Example 2 - One stack actually one stack on disk, two rois
        ----------------------------------------------------------
            stacks = [[&#39;stack.tif&#39;]]
            ROIs = [[(0,0,24,24), (24,24,24,24)]]

        &#39;&#39;&#39;
        N_rois = len(ROIs)
        N_stacks = len(stacks)
 
        # A) Stacks
        # FIXME: Validity checks for stacks
        self.stacks = stacks
        
        # B) Determine ROIs relationship to the stacks
        self.print_callback(&#39;Determining stack/ROI relationships in movemeter&#39;)
        if N_rois &gt; 1:
            # Separate ROIs for each stack
            self.ROIs = ROIs
        elif N_rois == 1:
            # Same ROIs for all the stacks
            self.ROIs = [ROIs[0] for i in range(len(stacks))]    
        elif N_rois != N_stacks:
            raise ValueError(
                    f&#34;Stacks and ROIs lenghts do not match ({N_stacks} vs {N_rois})&#34;)
        
        # Make all ROIs into ints
        self.ROIs = [[[int(x), int(y), int(w), int(h)] for x,y,w,h in ROI] for ROI in self.ROIs]

    
    def measure_rotation(self, stack_i, optimized=False):
        &#39;&#39;&#39;Measures rotation changes over time within the ROIs

        Arguments
        ---------
        stacks_i : int
            The index of the stack to analyse (order as in set_data)
        optimized : bool
            Run the optimized version for many ROIs (experimental)
        &#39;&#39;&#39;
        return self.measure_movement(
                stack_i, optimized=optimized, _rotation=True)
   

    def measure_brightness(self, stack_i, relative=&#39;roi&#39;):
        &#39;&#39;&#39;Measures brightness changes over time within the ROIs
        
        Brightness measurement is independent of the cross-correlation
        backends.

        Arguments
        ---------
        stack_i : int
            The index of the stack to analyse (order as in set_data)
        relative : string or None
            How to report the brightness change calues.
            If None or &#34;absolute&#34;, values are absolute.
            If &#34;roimin&#34;, values relative to the minimum of each ROI.
            If &#34;roi&#34;, values relative to each ROI (between 0 and 1)
        &#39;&#39;&#39;
        image_fns = self.stacks[stack_i]
        ROIs = self.ROIs[stack_i]

        results = [[[],[]] for roi in ROIs]
        
        for fn in image_fns:
            for image in self._imread(fn):
                for i_roi, roi in enumerate(ROIs):
                    x,y,w,h = roi
                    value = np.mean(image[y:y+h, x:x+w])

                    results[i_roi][0].append(value)
        
        if relative is None or relative == &#34;absolute&#34;:
            pass
        elif relative == &#34;roimin&#34;:
            for rresults in results:
                divider = np.min(rresults[0])
                rresults[0] = (np.array(rresults[0])/divider).tolist()
        elif relative == &#34;roi&#34;:
            for rresults in results:
                minval = np.min(rresults[0])
                maxval = np.max(rresults[0])
                rresults[0] = ((np.array(rresults[0])-minval)/maxval).tolist()
        else:
            raise ValueError(f&#34;Unkown value for &#39;relative&#39;: {relative}&#34;)

        # Dirty fix to brightness results to work with XY motion
        # analysis based code elsewhere (add zero y component)
        for rresults in results:
            rresults[1] = (np.array(rresults[0])*0).tolist()

        return results


    def measure_movement(self, stack_i, max_movement=False, optimized=False, _rotation=False):
        &#39;&#39;&#39;Measures translational movement over time within the ROIs.

        Arguments
        ---------
        stack_i : int
            The index of the stack to analyse (order as in set_data)
        max_movement : int
            Speed up the computation (and increase reliability) by
            specifying the maximum translation between subsequent frames,
            in pixels. If not specified, uses self.max_movement
        optimized : bool
            Run the optimized version for many ROIs (experimental)

        Returns
        -------
        results_stack_i : list of lists
            [
              results_ROI1, results_ROI2, ...
            ]
            
            results_ROIj = [movement_points_in_X, movement_points_in_Y]

        &#39;&#39;&#39;
        if not max_movement:
            max_movement = self.max_movement

        start_time = time.time()
        self.print_callback(
                &#39;Starting to analyse stack {}/{}&#39;.format(
                    stack_i+1, len(self.stacks)))
        
        # Select target _measure_movement
        if optimized:
            self.print_callback(&#39;Targeting to the optimized version&#39;)
            target = self._measure_movement_optimized_xray_data
        else:
            target = self._measure_movement

        if self.multiprocess:
        
            # -----------------------------
            # Temporary EOFError fix:
            # When starting new processes, the whole
            # Movemeter class ends up pickled. Because print_callback in
            # tkgui is set to some tkinter object, the whole tkinter
            # session gets pickled. On Windows, for some reason, this
            # object cannot be pickeld.
            #
            # While this works now, this is not a good fix because if
            # anyone adds something unpickable to a Movemeter object,
            # the same error happens again.
            #
            print_callback = self.print_callback
            self.print_callback = None
            # -----------------------------


            # Create multiprocessing manager and a inter-processes
            # shared results_list
            manager = multiprocessing.Manager()
            results_list = manager.list()
            messages = manager.list()
            for i in range(self.multiprocess):
                results_list.append([])
            
   
            # Create and start workers
            workers = []
            work_chunk = int(len(self.ROIs[stack_i]) / self.multiprocess)
            for i_worker in range(self.multiprocess): 

                if i_worker == self.multiprocess - 1:
                    worker_ROIs = self.ROIs[stack_i][i_worker*work_chunk:]
                else:
                    worker_ROIs = self.ROIs[stack_i][i_worker*work_chunk:(i_worker+1)*work_chunk]
                
                worker = multiprocessing.Process(
                        target=target,
                        args=[self.stacks[stack_i], worker_ROIs],
                        kwargs={
                            &#39;max_movement&#39;: max_movement,
                            &#39;results_list&#39;: results_list,
                            &#39;worker_i&#39;: i_worker,
                            &#39;messages&#39;: messages,
                            &#39;_rotation&#39;: _rotation}
                        )
                
                workers.append(worker)
                worker.start()

            # Wait until all workers get ready
            for i_worker, worker in enumerate(workers):
                print_callback(&#39;Waiting worker #{} to finish&#39;.format(
                    i_worker+1))
                while worker.is_alive():
                    if messages:
                        print_callback(messages[-1])
                    time.sleep(1)
                worker.join()

            # Combine workers&#39; results
            print_callback(&#39;Combining results from different workers&#39;)
            results = []
            for worker_results in results_list:
                results.extend(worker_results)

            # -----------------------------
            # FIX EOFError, latter part, see above
            self.print_callback = print_callback
            # -----------------------------


        else:
            # So nice and simple without multiprocessing ;)
            results = target(
                    self.stacks[stack_i],
                    self.ROIs[stack_i],
                    max_movement=max_movement,
                    _rotation=_rotation
                    )
        
        self.print_callback(
                &#39;Finished stack {}/{} in {} seconds&#39;.format(
                    stack_i+1, len(self.stacks), time.time()-start_time))

        return results 

    

    def get_metadata(self, stack_i, image_i=0):
        &#39;&#39;&#39;Get metadata for stack number stack_i.
        
        Arguments
        ---------
        stack_i : int
            The index of the stack to analyse (order as in set_data)
        image_i : int
            Optionally, the index of the image from which to read
            the metadata from. Can be different especially if stack
            is made of separate images on disk.

        Returns
        -------
        tags: dict
            A dictionary of exifread objects. See exifread documentation.
        &#39;&#39;&#39;
        # FIXME - Instead of using exifread here, we should
        # implement metadata reading (using exifread or something else)
        # in the image loading backends
        if exifread is None:
            return {}
        with open(self.stacks[stack_i][image_i], &#39;rb&#39;) as fp:
            tags = exifread.process_file(fp)

        return tags
    

    def get_image_resolution(self, stack_i):
        &#39;&#39;&#39;Returns resolution of the images in stack_i.

        Currently opens the first image to see the resolution (slow).
        Would be better to read from the metadata directly...
        
        Arguments
        ----------
        stack_i : int
            The index of the stack to analyse (order as in set_data)

        Returns
        -------
        width : int
            Width of the image, in pixels
        height : int
            Height of the image, in pixels

        &#39;&#39;&#39;
        height, width = self._imread(self.stacks[stack_i][0])[0].shape
        return width, height</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="movemeter.movemeter.Movemeter.measure_brightness_opt"><code class="name">var <span class="ident">measure_brightness_opt</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="movemeter.movemeter.Movemeter.create_mask_image"><code class="name flex">
<span>def <span class="ident">create_mask_image</span></span>(<span>self, image_fns)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a min-mask image</p>
<p>The problem sometimes with cross-correlation analysis is that
the moving features are semi-transparent or faint while there's
a stationary, strong-featured background.</p>
<p>Subtracting the min-mask image of a stack can be used to remove
some stationary features -&gt; Working motion detection.</p>
<p>Seems to work well with microsaccades X-ray projections data.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>image_fns</code></strong> :&ensp;<code>list</code> of <code>strings</code></dt>
<dd>Filenames of the images in the stack</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>mask_image</code></strong> :&ensp;<code>2D numpy array</code></dt>
<dd>Min image of the stack</dd>
</dl></div>
</dd>
<dt id="movemeter.movemeter.Movemeter.get_image_resolution"><code class="name flex">
<span>def <span class="ident">get_image_resolution</span></span>(<span>self, stack_i)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns resolution of the images in stack_i.</p>
<p>Currently opens the first image to see the resolution (slow).
Would be better to read from the metadata directly&hellip;</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>stack_i</code></strong> :&ensp;<code>int</code></dt>
<dd>The index of the stack to analyse (order as in set_data)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>width</code></strong> :&ensp;<code>int</code></dt>
<dd>Width of the image, in pixels</dd>
<dt><strong><code>height</code></strong> :&ensp;<code>int</code></dt>
<dd>Height of the image, in pixels</dd>
</dl></div>
</dd>
<dt id="movemeter.movemeter.Movemeter.get_metadata"><code class="name flex">
<span>def <span class="ident">get_metadata</span></span>(<span>self, stack_i, image_i=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Get metadata for stack number stack_i.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>stack_i</code></strong> :&ensp;<code>int</code></dt>
<dd>The index of the stack to analyse (order as in set_data)</dd>
<dt><strong><code>image_i</code></strong> :&ensp;<code>int</code></dt>
<dd>Optionally, the index of the image from which to read
the metadata from. Can be different especially if stack
is made of separate images on disk.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tags</code></strong> :&ensp;<code>dict</code></dt>
<dd>A dictionary of exifread objects. See exifread documentation.</dd>
</dl></div>
</dd>
<dt id="movemeter.movemeter.Movemeter.measure_brightness"><code class="name flex">
<span>def <span class="ident">measure_brightness</span></span>(<span>self, stack_i, relative='roi')</span>
</code></dt>
<dd>
<div class="desc"><p>Measures brightness changes over time within the ROIs</p>
<p>Brightness measurement is independent of the cross-correlation
backends.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>stack_i</code></strong> :&ensp;<code>int</code></dt>
<dd>The index of the stack to analyse (order as in set_data)</dd>
<dt><strong><code>relative</code></strong> :&ensp;<code>string</code> or <code>None</code></dt>
<dd>How to report the brightness change calues.
If None or "absolute", values are absolute.
If "roimin", values relative to the minimum of each ROI.
If "roi", values relative to each ROI (between 0 and 1)</dd>
</dl></div>
</dd>
<dt id="movemeter.movemeter.Movemeter.measure_movement"><code class="name flex">
<span>def <span class="ident">measure_movement</span></span>(<span>self, stack_i, max_movement=False, optimized=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Measures translational movement over time within the ROIs.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>stack_i</code></strong> :&ensp;<code>int</code></dt>
<dd>The index of the stack to analyse (order as in set_data)</dd>
<dt><strong><code>max_movement</code></strong> :&ensp;<code>int</code></dt>
<dd>Speed up the computation (and increase reliability) by
specifying the maximum translation between subsequent frames,
in pixels. If not specified, uses self.max_movement</dd>
<dt><strong><code>optimized</code></strong> :&ensp;<code>bool</code></dt>
<dd>Run the optimized version for many ROIs (experimental)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>results_stack_i</code></strong> :&ensp;<code>list</code> of <code>lists</code></dt>
<dd>
<p>[
results_ROI1, results_ROI2, &hellip;
]</p>
<p>results_ROIj = [movement_points_in_X, movement_points_in_Y]</p>
</dd>
</dl></div>
</dd>
<dt id="movemeter.movemeter.Movemeter.measure_rotation"><code class="name flex">
<span>def <span class="ident">measure_rotation</span></span>(<span>self, stack_i, optimized=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Measures rotation changes over time within the ROIs</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>stacks_i</code></strong> :&ensp;<code>int</code></dt>
<dd>The index of the stack to analyse (order as in set_data)</dd>
<dt><strong><code>optimized</code></strong> :&ensp;<code>bool</code></dt>
<dd>Run the optimized version for many ROIs (experimental)</dd>
</dl></div>
</dd>
<dt id="movemeter.movemeter.Movemeter.set_data"><code class="name flex">
<span>def <span class="ident">set_data</span></span>(<span>self, stacks, ROIs)</span>
</code></dt>
<dd>
<div class="desc"><p>Set stack filenames and ROIs (regions of interest) to be analysed.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>stacks</code></strong> :&ensp;<code>list</code> of <code>lists</code> of <code>filenames</code></dt>
<dd>List of filename lists. In format
[
[stack1_im1, stack1_im2&hellip;],
[stack2_im1, stack2_im2], &hellip;
]</dd>
<dt><strong><code>ROIs</code></strong> :&ensp;<code>list</code> of <code>lists</code> of <code>ROIs</code></dt>
<dd>
<p>[
[ROI1_for_stack1, ROI2_for_stack1, &hellip;],
[ROI1_for_stack2, &hellip;], &hellip;
]</p>
<p>ROI format: (x, y, w, h)</p>
<p>If the list has length, it means use the same provided
ROIs for all stacks.</p>
</dd>
</dl>
<h2 id="example-1-one-stack-made-separate-images-one-roi">Example 1 - One stack made separate images, one roi</h2>
<pre><code>stacks = [['frame1.tif', 'frame2.tif', ...]]
ROIs = [[(0,0,24,24)]]
</code></pre>
<h2 id="example-2-one-stack-actually-one-stack-on-disk-two-rois">Example 2 - One stack actually one stack on disk, two rois</h2>
<pre><code>stacks = [['stack.tif']]
ROIs = [[(0,0,24,24), (24,24,24,24)]]
</code></pre></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<a href='../index.html'><- Back to All Docs</a><br>
<a href="javascript:history.back()"><- Back one page</a>
<div class="toc">
<ul>
<li><a href="#alternatives">Alternatives</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="movemeter" href="index.html">movemeter</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="movemeter.movemeter.Movemeter" href="#movemeter.movemeter.Movemeter">Movemeter</a></code></h4>
<ul class="">
<li><code><a title="movemeter.movemeter.Movemeter.create_mask_image" href="#movemeter.movemeter.Movemeter.create_mask_image">create_mask_image</a></code></li>
<li><code><a title="movemeter.movemeter.Movemeter.get_image_resolution" href="#movemeter.movemeter.Movemeter.get_image_resolution">get_image_resolution</a></code></li>
<li><code><a title="movemeter.movemeter.Movemeter.get_metadata" href="#movemeter.movemeter.Movemeter.get_metadata">get_metadata</a></code></li>
<li><code><a title="movemeter.movemeter.Movemeter.measure_brightness" href="#movemeter.movemeter.Movemeter.measure_brightness">measure_brightness</a></code></li>
<li><code><a title="movemeter.movemeter.Movemeter.measure_brightness_opt" href="#movemeter.movemeter.Movemeter.measure_brightness_opt">measure_brightness_opt</a></code></li>
<li><code><a title="movemeter.movemeter.Movemeter.measure_movement" href="#movemeter.movemeter.Movemeter.measure_movement">measure_movement</a></code></li>
<li><code><a title="movemeter.movemeter.Movemeter.measure_rotation" href="#movemeter.movemeter.Movemeter.measure_rotation">measure_rotation</a></code></li>
<li><code><a title="movemeter.movemeter.Movemeter.set_data" href="#movemeter.movemeter.Movemeter.set_data">set_data</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.1</a>.</p>
</footer>
</body>
</html>
